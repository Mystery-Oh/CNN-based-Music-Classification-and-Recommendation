{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_DIR = 'audio_files/fma_small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tids_from_directory(audio_dir):\n",
    "    tids = []\n",
    "    for _, dirnames, files in os.walk(audio_dir):\n",
    "        if dirnames == []:\n",
    "            tids.extend(int(file[:-4]) for file in files)\n",
    "    return tids\n",
    "\n",
    "def get_audio_path(audio_dir, track_id):\n",
    "    tid_str = '{:06d}'.format(track_id)\n",
    "    return os.path.join(audio_dir, tid_str[:3], tid_str + '.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tids = get_tids_from_directory(AUDIO_DIR)\n",
    "print(len(tids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spectogram(track_id):\n",
    "    filename = get_audio_path(AUDIO_DIR, track_id)\n",
    "    y, sr = librosa.load(filename)\n",
    "    spect = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=1024)\n",
    "    spect = librosa.power_to_db(spect, ref=np.max)\n",
    "    return spect.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spect(track_id):\n",
    "    spect = create_spectogram(track_id)\n",
    "    print(spect.shape)\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(spect.T, y_axis='mel', fmax=8000, x_axis='time')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'audio_files/tracks.csv'\n",
    "tracks = pd.read_csv(filepath, index_col=0, header=[0, 1])\n",
    "keep_cols = [('set', 'split'), ('set', 'subset'), ('track', 'genre_top')]\n",
    "\n",
    "df_all = tracks[keep_cols]\n",
    "df_all = df_all[df_all[('set', 'subset')] == 'small']\n",
    "\n",
    "df_all['track_id'] = df_all.index\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_genres = {'Electronic': 1, 'Experimental': 2, 'Folk': 3, 'Hip-Hop': 4,\n",
    "               'Instrumental': 5, 'International': 6, 'Pop': 7, 'Rock': 8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_array(df):\n",
    "    genres = []\n",
    "    X_spect = np.empty((0, 640, 128))\n",
    "    count = 0\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            count += 1\n",
    "            track_id = int(row['track_id'])\n",
    "            genre = str(row[('track', 'genre_top')])\n",
    "            spect = create_spectogram(track_id)\n",
    "\n",
    "            spect = spect[:640, :]\n",
    "            X_spect = np.append(X_spect, [spect], axis=0)\n",
    "            genres.append(dict_genres[genre])\n",
    "            if count % 100 == 0:\n",
    "                print(\"Currently processing: \", count)\n",
    "        except:\n",
    "            print(\"Couldn't process: \", count)\n",
    "            continue\n",
    "    y_arr = np.array(genres)\n",
    "    return X_spect, y_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_all[df_all[('set', 'split')] == 'training']\n",
    "df_valid = df_all[df_all[('set', 'split')] == 'validation']\n",
    "df_test = df_all[df_all[('set', 'split')] == 'test']\n",
    "\n",
    "print(df_train.shape, df_valid.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = create_array(df_test)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_raw = librosa.db_to_power(X_test, ref=1.0)\n",
    "X_test_log = np.log(X_test_raw)\n",
    "\n",
    "X_test_torch = torch.FloatTensor(X_test_log)\n",
    "y_test_torch = torch.LongTensor(y_test - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('test_arr', X_test_log, y_test - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, y_valid = create_array(df_valid)\n",
    "X_valid_raw = librosa.db_to_power(X_valid, ref=1.0)\n",
    "X_valid_log = np.log(X_valid_raw)\n",
    "\n",
    "np.savez('valid_arr', X_valid_log, y_valid - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataFrameIntoSmaller(df, chunkSize=1600):\n",
    "    listOfDf = list()\n",
    "    numberChunks = len(df) // chunkSize + 1\n",
    "    for i in range(numberChunks):\n",
    "        listOfDf.append(df[i * chunkSize:(i + 1) * chunkSize])\n",
    "    return listOfDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listDf = splitDataFrameIntoSmaller(df_train)\n",
    "X_train_list = []\n",
    "y_train_list = []\n",
    "\n",
    "for i, sub_df in enumerate(listDf):\n",
    "    print(f\"Processing train chunk {i + 1}/{len(listDf)}\")\n",
    "    X_chunk, y_chunk = create_array(sub_df)\n",
    "    X_train_list.append(X_chunk)\n",
    "    y_train_list.append(y_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate(X_train_list, axis=0)\n",
    "y_train = np.concatenate(y_train_list, axis=0)\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw = librosa.db_to_power(X_train, ref=1.0)\n",
    "X_train_log = np.log(X_train_raw)\n",
    "\n",
    "y_train = y_train - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "\n",
    "X_train, y_train = unison_shuffled_copies(X_train_log, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('shuffled_train', X_train, y_train)\n",
    "np.savez('shuffled_valid', X_valid_log, y_valid - 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
